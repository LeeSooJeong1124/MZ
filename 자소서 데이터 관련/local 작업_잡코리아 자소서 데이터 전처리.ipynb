{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "313985ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv('자소서(0).csv',encoding='cp949')\n",
    "df2=pd.read_csv('자소서(1).csv',encoding='cp949')\n",
    "df3=pd.read_csv('자소서(2).csv',encoding='cp949')\n",
    "df4=pd.read_csv('자소서11-20.csv',encoding='cp949')\n",
    "df5=pd.read_csv('자소서21-28.csv',encoding='cp949')\n",
    "df6=pd.read_csv('자소서(31).csv',encoding='cp949')\n",
    "df7=pd.read_csv('자소서(32).csv',encoding='cp949')\n",
    "df8=pd.read_csv('자소서(34).csv',encoding='cp949')\n",
    "df9=pd.read_csv('자소서(35).csv',encoding='cp949')\n",
    "df10=pd.read_csv('자소서(36_84).csv',encoding='cp949')\n",
    "df11=pd.read_csv('자소서(39).csv',encoding='cp949')\n",
    "df12=pd.read_csv('자소서(44).csv',encoding='cp949')\n",
    "df13=pd.read_csv('자소서(47).csv',encoding='cp949')\n",
    "df14=pd.read_csv('자소서(48).csv',encoding='cp949')\n",
    "df15=pd.read_csv('자소서(49).csv',encoding='cp949')\n",
    "\n",
    "df16=pd.read_csv('자소서(3).csv',encoding='cp949')\n",
    "df17=pd.read_csv('자소서(4).csv',encoding='utf-8-sig')\n",
    "df18=pd.read_csv('자소서(161).csv',encoding='cp949')\n",
    "df19=pd.read_csv('자소서(171).csv',encoding='cp949')\n",
    "df20=pd.read_csv('자소서(181).csv',encoding='cp949')\n",
    "df21=pd.read_csv('자소서(191).csv',encoding='cp949')\n",
    "df22=pd.read_csv('자소서(251).csv',encoding='utf-8-sig')\n",
    "df23=pd.read_csv('자소서(261).csv',encoding='utf-8-sig')\n",
    "df24=pd.read_csv('자소서(271).csv',encoding='utf-8-sig')\n",
    "df25=pd.read_csv('자소서(281).csv',encoding='utf-8-sig')\n",
    "df26=pd.read_csv('자소서(291).csv',encoding='utf-8-sig')\n",
    "df27=pd.read_csv('자소서(301).csv',encoding='utf-8-sig')\n",
    "df28=pd.read_csv('자소서(311).csv',encoding='utf-8-sig')\n",
    "df29=pd.read_csv('자소서(321).csv',encoding='utf-8-sig')\n",
    "df30=pd.read_csv('자소서(331).csv',encoding='utf-8-sig')\n",
    "df31=pd.read_csv('자소서(351).csv',encoding='utf-8-sig')\n",
    "df32=pd.read_csv('자소서(410).csv',encoding='cp949')\n",
    "df33=pd.read_csv('자소서(412).csv',encoding='cp949')\n",
    "df34=pd.read_csv('자소서(1101).csv',encoding='cp949')\n",
    "df35=pd.read_csv('자소서(1111).csv',encoding='cp949')\n",
    "df36=pd.read_csv('자소서(1121).csv',encoding='cp949')\n",
    "df37=pd.read_csv('자소서(1131).csv',encoding='cp949')\n",
    "df38=pd.read_csv('자소서(2141).csv',encoding='cp949')\n",
    "df39=pd.read_csv('자소서(2151).csv',encoding='cp949')\n",
    "\n",
    "\n",
    "df40=pd.read_csv('자소서(321_).csv',encoding='utf-8-sig')\n",
    "df41=pd.read_csv('자소서(2111_).csv',encoding='utf-8-sig')\n",
    "df42=pd.read_csv('자소서(2101_).csv',encoding='utf-8-sig')\n",
    "df43=pd.read_csv('자소서(291_).csv',encoding='utf-8-sig')\n",
    "df44=pd.read_csv('자소서(281_).csv',encoding='utf-8-sig')\n",
    "df45=pd.read_csv('자소서(271_).csv',encoding='utf-8-sig')\n",
    "df46=pd.read_csv('자소서(278까지).csv',encoding='utf-8-sig')\n",
    "df47=pd.read_csv('자소서(261_).csv',encoding='utf-8-sig')\n",
    "df48=pd.read_csv('자소서(251_).csv',encoding='utf-8-sig')\n",
    "df49=pd.read_csv('자소서(241_).csv',encoding='utf-8-sig')\n",
    "df50=pd.read_csv('자소서(231_).csv',encoding='utf-8-sig')\n",
    "df51=pd.read_csv('자소서(1121_).csv',encoding='utf-8-sig')\n",
    "df52=pd.read_csv('자소서(1121_).csv',encoding='utf-8-sig')\n",
    "df53=pd.read_csv('자소서(1111_).csv',encoding='utf-8-sig')\n",
    "df54=pd.read_csv('자소서(1101_).csv',encoding='utf-8-sig')\n",
    "df55=pd.read_csv('자소서(191_).csv',encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b22c9a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_=[0 for i in range(39)]\n",
    "len(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84dc82f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df39\n"
     ]
    }
   ],
   "source": [
    "print('df'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0498ec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>연합뉴스TV를 선택한 이유(지원동기 및 방송철학) (800자)</td>\n",
       "      <td>\"지원 동기 - 水魚之交, 내 영혼의 단짝 연합뉴스TV\"\\n\\n2020년 상반기, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>지원 분야를 잘 수행할 수 있다고 생각하는 이유(성장과정 및 준비사항) (800자)</td>\n",
       "      <td>\"성장 과정 - 상자 밖으로 생각하는 사람\"\\n\\n막둥이로 태어나, 작은 행동 하나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>연합뉴스TV가 본인을 선발해야 하는 이유 (800자)</td>\n",
       "      <td>\"함께하던 시청자에서 함께하는 신입 사원으로\"\\n\\n방송국에서는 본사의 시청자로서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>상기 내용 외에 추가하고자 하는 사항(입사 후 포부 및 자신의 업무경험 등 면접관에...</td>\n",
       "      <td>\"입사 후 포부 1 - 메타버스, MZ세대 친화형 콘텐츠로 시청률 높이기\"\\n\\n본...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>피에스앤마케팅(주)</td>\n",
       "      <td>자발적으로 더 높은 수준의 목표를 세우고 도전했던 경험 중 어려웠던 문제나 상황은 ...</td>\n",
       "      <td>OOOOO OOOO 활동 중 O브랜드와 관련하여 팀 단위로 홍보영상을 제작한 경험이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31511</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>귀하의 성장과정을 통해 본인을 소개하여 주십시오(가족, 가치관, 성격, 학창시절 등...</td>\n",
       "      <td>\"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31512</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>취미 및 특기(1000자 이내)</td>\n",
       "      <td>취미는 야구 관람입니다. 동아리 회원들과 월 1회정도 야구 관람을 하며 스트레스 해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31513</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>인생에서 반드시 이루고 싶은 목표는 무엇이고, 목표를 이루기 위해 어떠한 노력을 기...</td>\n",
       "      <td>\"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31514</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>여신전문금융업무를 위해 필요한 역량은 무엇이고, 이러한 점을 갖추기 위해 그동안 준...</td>\n",
       "      <td>여신전문금융업무의 전산직에서는 금융시장에 필요한 IT기술을 접목하여 사용자의 금융환...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31515</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>창의적인 사고와 도전정신을 발휘하여 성취를 이뤄낸 사례가 있다면 기술하시오.(100...</td>\n",
       "      <td>\"‘낯설다’를 ‘익숙하다’로\"\\n\\n새로운 분야에 도전하여 뒤따르는 성취감은 제 자...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          company                                                  Q  \\\n",
       "0         연합뉴스티브이                 연합뉴스TV를 선택한 이유(지원동기 및 방송철학) (800자)   \n",
       "1         연합뉴스티브이     지원 분야를 잘 수행할 수 있다고 생각하는 이유(성장과정 및 준비사항) (800자)   \n",
       "2         연합뉴스티브이                      연합뉴스TV가 본인을 선발해야 하는 이유 (800자)   \n",
       "3         연합뉴스티브이  상기 내용 외에 추가하고자 하는 사항(입사 후 포부 및 자신의 업무경험 등 면접관에...   \n",
       "4      피에스앤마케팅(주)  자발적으로 더 높은 수준의 목표를 세우고 도전했던 경험 중 어려웠던 문제나 상황은 ...   \n",
       "...           ...                                                ...   \n",
       "31511     ㈜IBK캐피탈  귀하의 성장과정을 통해 본인을 소개하여 주십시오(가족, 가치관, 성격, 학창시절 등...   \n",
       "31512     ㈜IBK캐피탈                                  취미 및 특기(1000자 이내)   \n",
       "31513     ㈜IBK캐피탈  인생에서 반드시 이루고 싶은 목표는 무엇이고, 목표를 이루기 위해 어떠한 노력을 기...   \n",
       "31514     ㈜IBK캐피탈  여신전문금융업무를 위해 필요한 역량은 무엇이고, 이러한 점을 갖추기 위해 그동안 준...   \n",
       "31515     ㈜IBK캐피탈  창의적인 사고와 도전정신을 발휘하여 성취를 이뤄낸 사례가 있다면 기술하시오.(100...   \n",
       "\n",
       "                                                       A  \n",
       "0      \"지원 동기 - 水魚之交, 내 영혼의 단짝 연합뉴스TV\"\\n\\n2020년 상반기, ...  \n",
       "1      \"성장 과정 - 상자 밖으로 생각하는 사람\"\\n\\n막둥이로 태어나, 작은 행동 하나...  \n",
       "2      \"함께하던 시청자에서 함께하는 신입 사원으로\"\\n\\n방송국에서는 본사의 시청자로서 ...  \n",
       "3      \"입사 후 포부 1 - 메타버스, MZ세대 친화형 콘텐츠로 시청률 높이기\"\\n\\n본...  \n",
       "4      OOOOO OOOO 활동 중 O브랜드와 관련하여 팀 단위로 홍보영상을 제작한 경험이...  \n",
       "...                                                  ...  \n",
       "31511  \"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...  \n",
       "31512  취미는 야구 관람입니다. 동아리 회원들과 월 1회정도 야구 관람을 하며 스트레스 해...  \n",
       "31513  \"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...  \n",
       "31514  여신전문금융업무의 전산직에서는 금융시장에 필요한 IT기술을 접목하여 사용자의 금융환...  \n",
       "31515  \"‘낯설다’를 ‘익숙하다’로\"\\n\\n새로운 분야에 도전하여 뒤따르는 성취감은 제 자...  \n",
       "\n",
       "[31516 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list=[df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32,df33,df34,df35,df36,df37,df38,df39,df40,df41,df42,df43,df44,df45,df46,df47,df48,df49,df50,df51,df52,df53,df54,df55]\n",
    "df_all=pd.concat(df_list,ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f80c8188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>연합뉴스TV를 선택한 이유(지원동기 및 방송철학) (800자)</td>\n",
       "      <td>\"지원 동기 - 水魚之交, 내 영혼의 단짝 연합뉴스TV\"\\n\\n2020년 상반기, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>지원 분야를 잘 수행할 수 있다고 생각하는 이유(성장과정 및 준비사항) (800자)</td>\n",
       "      <td>\"성장 과정 - 상자 밖으로 생각하는 사람\"\\n\\n막둥이로 태어나, 작은 행동 하나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>연합뉴스TV가 본인을 선발해야 하는 이유 (800자)</td>\n",
       "      <td>\"함께하던 시청자에서 함께하는 신입 사원으로\"\\n\\n방송국에서는 본사의 시청자로서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>연합뉴스티브이</td>\n",
       "      <td>상기 내용 외에 추가하고자 하는 사항(입사 후 포부 및 자신의 업무경험 등 면접관에...</td>\n",
       "      <td>\"입사 후 포부 1 - 메타버스, MZ세대 친화형 콘텐츠로 시청률 높이기\"\\n\\n본...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>피에스앤마케팅(주)</td>\n",
       "      <td>자발적으로 더 높은 수준의 목표를 세우고 도전했던 경험 중 어려웠던 문제나 상황은 ...</td>\n",
       "      <td>OOOOO OOOO 활동 중 O브랜드와 관련하여 팀 단위로 홍보영상을 제작한 경험이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25214</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>귀하의 성장과정을 통해 본인을 소개하여 주십시오(가족, 가치관, 성격, 학창시절 등...</td>\n",
       "      <td>\"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25215</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>취미 및 특기(1000자 이내)</td>\n",
       "      <td>취미는 야구 관람입니다. 동아리 회원들과 월 1회정도 야구 관람을 하며 스트레스 해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25216</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>인생에서 반드시 이루고 싶은 목표는 무엇이고, 목표를 이루기 위해 어떠한 노력을 기...</td>\n",
       "      <td>\"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>여신전문금융업무를 위해 필요한 역량은 무엇이고, 이러한 점을 갖추기 위해 그동안 준...</td>\n",
       "      <td>여신전문금융업무의 전산직에서는 금융시장에 필요한 IT기술을 접목하여 사용자의 금융환...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25218</th>\n",
       "      <td>㈜IBK캐피탈</td>\n",
       "      <td>창의적인 사고와 도전정신을 발휘하여 성취를 이뤄낸 사례가 있다면 기술하시오.(100...</td>\n",
       "      <td>\"‘낯설다’를 ‘익숙하다’로\"\\n\\n새로운 분야에 도전하여 뒤따르는 성취감은 제 자...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          company                                                  Q  \\\n",
       "0         연합뉴스티브이                 연합뉴스TV를 선택한 이유(지원동기 및 방송철학) (800자)   \n",
       "1         연합뉴스티브이     지원 분야를 잘 수행할 수 있다고 생각하는 이유(성장과정 및 준비사항) (800자)   \n",
       "2         연합뉴스티브이                      연합뉴스TV가 본인을 선발해야 하는 이유 (800자)   \n",
       "3         연합뉴스티브이  상기 내용 외에 추가하고자 하는 사항(입사 후 포부 및 자신의 업무경험 등 면접관에...   \n",
       "4      피에스앤마케팅(주)  자발적으로 더 높은 수준의 목표를 세우고 도전했던 경험 중 어려웠던 문제나 상황은 ...   \n",
       "...           ...                                                ...   \n",
       "25214     ㈜IBK캐피탈  귀하의 성장과정을 통해 본인을 소개하여 주십시오(가족, 가치관, 성격, 학창시절 등...   \n",
       "25215     ㈜IBK캐피탈                                  취미 및 특기(1000자 이내)   \n",
       "25216     ㈜IBK캐피탈  인생에서 반드시 이루고 싶은 목표는 무엇이고, 목표를 이루기 위해 어떠한 노력을 기...   \n",
       "25217     ㈜IBK캐피탈  여신전문금융업무를 위해 필요한 역량은 무엇이고, 이러한 점을 갖추기 위해 그동안 준...   \n",
       "25218     ㈜IBK캐피탈  창의적인 사고와 도전정신을 발휘하여 성취를 이뤄낸 사례가 있다면 기술하시오.(100...   \n",
       "\n",
       "                                                       A  \n",
       "0      \"지원 동기 - 水魚之交, 내 영혼의 단짝 연합뉴스TV\"\\n\\n2020년 상반기, ...  \n",
       "1      \"성장 과정 - 상자 밖으로 생각하는 사람\"\\n\\n막둥이로 태어나, 작은 행동 하나...  \n",
       "2      \"함께하던 시청자에서 함께하는 신입 사원으로\"\\n\\n방송국에서는 본사의 시청자로서 ...  \n",
       "3      \"입사 후 포부 1 - 메타버스, MZ세대 친화형 콘텐츠로 시청률 높이기\"\\n\\n본...  \n",
       "4      OOOOO OOOO 활동 중 O브랜드와 관련하여 팀 단위로 홍보영상을 제작한 경험이...  \n",
       "...                                                  ...  \n",
       "25214  \"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...  \n",
       "25215  취미는 야구 관람입니다. 동아리 회원들과 월 1회정도 야구 관람을 하며 스트레스 해...  \n",
       "25216  \"어릴 적 꿈\"\\n\\n초등학교 시절, 아버지께서 운영하시던 컴퓨터학원에서 원생들이 ...  \n",
       "25217  여신전문금융업무의 전산직에서는 금융시장에 필요한 IT기술을 접목하여 사용자의 금융환...  \n",
       "25218  \"‘낯설다’를 ‘익숙하다’로\"\\n\\n새로운 분야에 도전하여 뒤따르는 성취감은 제 자...  \n",
       "\n",
       "[25219 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUll값 들어간 거 지우기# 자소서(278까지).csv 465인덱스\n",
    "\n",
    "df_all.dropna(axis=0)\n",
    "df_all.drop_duplicates(['A'],inplace=True,ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "369ec6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('최종 데이터(잡코리아).csv',encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743d7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60fe076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e588c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a684e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetConvPoolLayer(object):\n",
    "    \"\"\"Pool Layer of a convolutional network \"\"\"\n",
    "\n",
    "    def __init__(self, rng, filter_shape, image_shape, poolsize=(2, 2), non_linear=\"tanh\"):\n",
    "        \"\"\"\n",
    "        Allocate a LeNetConvPoolLayer with shared variable internal parameters.\n",
    "        :type rng: numpy.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "        :type input: theano.tensor.dtensor4\n",
    "        :param input: symbolic image tensor, of shape image_shape\n",
    "        :type filter_shape: tuple or list of length 4\n",
    "        :param filter_shape: (number of filters, num input feature maps,\n",
    "                              filter height,filter width)\n",
    "        :type image_shape: tuple or list of length 4\n",
    "        :param image_shape: (batch size, num input feature maps,\n",
    "                             image height, image width)\n",
    "        :type poolsize: tuple or list of length 2\n",
    "        :param poolsize: the downsampling (pooling) factor (#rows,#cols)\n",
    "        \"\"\"\n",
    "\n",
    "        # assert image_shape[1] == filter_shape[1]\n",
    "        # self.input = input\n",
    "        self.filter_shape = filter_shape\n",
    "        self.image_shape = image_shape\n",
    "        self.poolsize = poolsize\n",
    "        self.non_linear = non_linear\n",
    "        # there are \"num input feature maps * filter height * filter width\"\n",
    "        # inputs to each hidden unit\n",
    "        fan_in = numpy.prod(filter_shape[1:])\n",
    "        # each unit in the lower layer receives a gradient from:\n",
    "        # \"num output feature maps * filter height * filter width\" /\n",
    "        #   pooling size\n",
    "        fan_out = (filter_shape[0] * numpy.prod(filter_shape[2:]) /numpy.prod(poolsize))\n",
    "        # initialize weights with random weights\n",
    "        if self.non_linear==\"none\" or self.non_linear==\"relu\":\n",
    "            self.W = theano.shared(numpy.asarray(rng.uniform(low=-0.01,high=0.01,size=filter_shape),\n",
    "                                                dtype=theano.config.floatX),borrow=True,name=\"W_conv\")\n",
    "        else:\n",
    "            W_bound = numpy.sqrt(6. / (fan_in + fan_out))\n",
    "            self.W = theano.shared(numpy.asarray(rng.uniform(low=-W_bound, high=W_bound, size=filter_shape),\n",
    "                dtype=theano.config.floatX),borrow=True,name=\"W_conv\")\n",
    "        b_values = numpy.zeros((filter_shape[0],), dtype=theano.config.floatX)\n",
    "        self.b = theano.shared(value=b_values, borrow=True, name=\"b_conv\")\n",
    "\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "    def set_input(self, input):\n",
    "        # convolve input feature maps with filters\n",
    "        conv_out = conv.conv2d(input=input, filters=self.W,filter_shape=self.filter_shape, image_shape=self.image_shape)\n",
    "        if self.non_linear==\"tanh\":\n",
    "            conv_out_tanh = T.tanh(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "            output = downsample.max_pool_2d(input=conv_out_tanh, ds=self.poolsize, ignore_border=True)\n",
    "        elif self.non_linear==\"relu\":\n",
    "            conv_out_tanh = ReLU(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "            output = downsample.max_pool_2d(input=conv_out_tanh, ds=self.poolsize, ignore_border=True)\n",
    "        else:\n",
    "            pooled_out = downsample.max_pool_2d(input=conv_out, ds=self.poolsize, ignore_border=True)\n",
    "            output = pooled_out + self.b.dimshuffle('x', 0, 'x', 'x')\n",
    "        return output\n",
    "\n",
    "    def predict(self, new_data, batch_size):\n",
    "        \"\"\"\n",
    "        predict for new data\n",
    "        \"\"\"\n",
    "        img_shape = None#(batch_size, 1, self.image_shape[2], self.image_shape[3])\n",
    "        conv_out = conv.conv2d(input=new_data, filters=self.W, filter_shape=self.filter_shape, image_shape=img_shape)\n",
    "        if self.non_linear==\"tanh\":\n",
    "            conv_out_tanh = T.tanh(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "            output = downsample.max_pool_2d(input=conv_out_tanh, ds=self.poolsize, ignore_border=True)\n",
    "        if self.non_linear==\"relu\":\n",
    "            conv_out_tanh = ReLU(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "            output = downsample.max_pool_2d(input=conv_out_tanh, ds=self.poolsize, ignore_border=True)\n",
    "        else:\n",
    "            pooled_out = downsample.max_pool_2d(input=conv_out, ds=self.poolsize, ignore_border=True)\n",
    "            output = pooled_out + self.b.dimshuffle('x', 0, 'x', 'x')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7f07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722565d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d2344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d44b2eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 50, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cv=0\n",
    "attr=0\n",
    "img_w=300\n",
    "filter_hs=[3,4,5]\n",
    "hidden_units=[100,2]\n",
    "dropout_rate=[0.5]\n",
    "shuffle_batch=True\n",
    "n_epochs=25\n",
    "batch_size=50\n",
    "lr_decay = 0.95\n",
    "conv_non_linear=\"relu\"\n",
    "#activations=[Iden]\n",
    "sqr_norm_lim=9\n",
    "non_static=True\n",
    "\n",
    "rng = np.random.RandomState(3435)\n",
    "img_h = 50#문장 길이\n",
    "filter_w = 300 #벡터 길이(word2vec:300)\n",
    "feature_maps = hidden_units[0]#은닉층의 node 수: default: 100\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "\n",
    "for filter_h in filter_hs:#filter_hs=[3,4,5]\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h - filter_h +1, img_w - filter_w +1))\n",
    "\n",
    "    \n",
    "parameters = [(\"image shape\",img_h,img_w),(\"filter shape\",filter_shapes), (\"hidden_units\",hidden_units),\n",
    "              (\"dropout\", dropout_rate), (\"batch_size\",batch_size),(\"non_static\", non_static),\n",
    "                (\"learn_decay\",lr_decay), (\"conv_non_linear\", conv_non_linear), (\"non_static\", non_static)\n",
    "                ,(\"sqr_norm_lim\",sqr_norm_lim),(\"shuffle_batch\",shuffle_batch)]\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b935f103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting theanoNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
      "     ---------------------------------------- 2.8/2.8 MB 10.1 MB/s eta 0:00:00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\drlis\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\drlis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from theano) (1.21.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\drlis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from theano) (1.7.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\drlis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from theano) (1.16.0)\n",
      "Building wheels for collected packages: theano\n",
      "  Building wheel for theano (setup.py): started\n",
      "  Building wheel for theano (setup.py): finished with status 'done'\n",
      "  Created wheel for theano: filename=Theano-1.0.5-py3-none-any.whl size=2668124 sha256=89c5e98243598a36e04456c95279f9cc5f383dae796cbb8e38e7039c56a2137f\n",
      "  Stored in directory: c:\\users\\drlis\\appdata\\local\\pip\\cache\\wheels\\26\\68\\6f\\745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n",
      "Successfully built theano\n",
      "Installing collected packages: theano\n",
      "Successfully installed theano-1.0.5\n"
     ]
    }
   ],
   "source": [
    "pip install theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12b75630",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39864\\3550072545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mzero_vec_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mzero_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mset_zero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzero_vec_tensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_subtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_vec_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mconv_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\theano\\tensor\\var.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;31m# Check if the number of dimensions isn't too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindex_dim_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'too many indices for array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;31m# Convert an Ellipsis if provided into an appropriate number of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "index = T.lscalar()\n",
    "x = T.tensor3('x')\n",
    "y = T.ivector('y')\n",
    "mair = T.fmatrix('mair')\n",
    "Words = theano.shared(value = U, name = \"Words\")\n",
    "zero_vec_tensor = T.vector()\n",
    "zero_vec = np.zeros(img_w)\n",
    "set_zero = theano.function([zero_vec_tensor], updates=[(Words, T.set_subtensor(Words[0,:], zero_vec_tensor))], allow_input_downcast=True)\n",
    "\n",
    "conv_layers = []\n",
    "\n",
    "for i in xrange(len(filter_hs)):\n",
    "    filter_shape = filter_shapes[i]\n",
    "    pool_size = pool_sizes[i]\n",
    "    conv_layer = LeNetConvPoolLayer(rng, image_shape=None,\n",
    "                            filter_shape=filter_shape, poolsize=pool_size, non_linear=conv_non_linear)\n",
    "    conv_layers.append(conv_layer)\n",
    "\n",
    "\n",
    "layer0_input = Words[T.cast(x.flatten(),dtype=\"int32\")].reshape((x.shape[0],x.shape[1],x.shape[2],Words.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0c010f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "U=np.array(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e088e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv_net(datasets,\n",
    "                   U,\n",
    "                   ofile,\n",
    "                   cv=0,\n",
    "                   attr=0,\n",
    "                   img_w=300,\n",
    "                   filter_hs=[3,4,5],\n",
    "                   hidden_units=[100,2],\n",
    "                   dropout_rate=[0.5],\n",
    "                   shuffle_batch=True,\n",
    "                   n_epochs=25,\n",
    "                   batch_size=50,\n",
    "                   lr_decay = 0.95,\n",
    "                   conv_non_linear=\"relu\",\n",
    "                   activations=[Iden],\n",
    "                   sqr_norm_lim=9,\n",
    "                   non_static=True):\n",
    "    \"\"\"\n",
    "    Train a simple conv net\n",
    "    img_h = sentence length (padded where necessary)\n",
    "    img_w = word vector length (300 for word2vec)\n",
    "    filter_hs = filter window sizes\n",
    "    hidden_units = [x,y] x is the number of feature maps (per filter window), and y is the penultimate layer\n",
    "    sqr_norm_lim = s^2 in the paper\n",
    "    lr_decay = adadelta decay parameter\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(3435)\n",
    "    img_h = len(datasets[0][0][0])#문장 길이\n",
    "    filter_w = img_w #벡터 길이(word2vec:300)\n",
    "    feature_maps = hidden_units[0]#은닉층의 node 수: default: 100\n",
    "    filter_shapes = []\n",
    "    pool_sizes = []\n",
    "    for filter_h in filter_hs:#filter_hs=[3,4,5]\n",
    "        filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "        pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n",
    "    parameters = [(\"image shape\",img_h,img_w),(\"filter shape\",filter_shapes), (\"hidden_units\",hidden_units),\n",
    "                  (\"dropout\", dropout_rate), (\"batch_size\",batch_size),(\"non_static\", non_static),\n",
    "                    (\"learn_decay\",lr_decay), (\"conv_non_linear\", conv_non_linear), (\"non_static\", non_static)\n",
    "                    ,(\"sqr_norm_lim\",sqr_norm_lim),(\"shuffle_batch\",shuffle_batch)]\n",
    "    print parameters\n",
    "\n",
    "    #define model architecture\n",
    "    index = T.lscalar()\n",
    "    x = T.tensor3('x')\n",
    "    y = T.ivector('y')\n",
    "    mair = T.fmatrix('mair')\n",
    "    Words = theano.shared(value = U, name = \"Words\")\n",
    "    zero_vec_tensor = T.vector()\n",
    "    zero_vec = np.zeros(img_w)\n",
    "    set_zero = theano.function([zero_vec_tensor], updates=[(Words, T.set_subtensor(Words[0,:], zero_vec_tensor))], allow_input_downcast=True)\n",
    "\n",
    "    conv_layers = []\n",
    "\n",
    "    for i in xrange(len(filter_hs)):\n",
    "        filter_shape = filter_shapes[i]\n",
    "        pool_size = pool_sizes[i]\n",
    "        conv_layer = LeNetConvPoolLayer(rng, image_shape=None,\n",
    "                                filter_shape=filter_shape, poolsize=pool_size, non_linear=conv_non_linear)\n",
    "        conv_layers.append(conv_layer)\n",
    "\n",
    "\n",
    "    layer0_input = Words[T.cast(x.flatten(),dtype=\"int32\")].reshape((x.shape[0],x.shape[1],x.shape[2],Words.shape[1]))\n",
    "\n",
    "    def convolve_user_statuses(statuses):\n",
    "        layer1_inputs = []\n",
    "\n",
    "        def sum_mat(mat, out):\n",
    "            z=ifelse(T.neq(T.sum(mat),T.constant(0)),T.constant(1),T.constant(0))\n",
    "            return  out+z, theano.scan_module.until(T.eq(z,T.constant(0)))\n",
    "\n",
    "        status_count,_ = theano.scan(fn = sum_mat, sequences=statuses, outputs_info=T.constant(0,dtype=theano.config.floatX))\n",
    "\n",
    "        # Slice-out dummy (zeroed) sentences\n",
    "        relv_input=statuses[:T.cast(status_count[-1],dtype='int32')].dimshuffle(0, 'x', 1, 2)\n",
    "\n",
    "        for conv_layer in conv_layers:\n",
    "            layer1_inputs.append(conv_layer.set_input(input=relv_input).flatten(2))\n",
    "\n",
    "        features = T.concatenate(layer1_inputs, axis=1)\n",
    "\n",
    "        avg_feat = T.max(features, axis=0)\n",
    "\n",
    "        return avg_feat\n",
    "\n",
    "    conv_feats, _ = theano.scan(fn= convolve_user_statuses, sequences= layer0_input)\n",
    "\n",
    "    # Add Mairesse features\n",
    "    layer1_input = T.concatenate([conv_feats, mair], axis=1)##mairesse_change\n",
    "    hidden_units[0] = feature_maps*len(filter_hs) + datasets[4].shape[1]##mairesse_change\n",
    "    classifier = MLPDropout(rng, input=layer1_input, layer_sizes=hidden_units, activations=activations, dropout_rates=dropout_rate)\n",
    "\n",
    "    svm_data = T.concatenate([classifier.layers[0].output, y.dimshuffle(0, 'x')], axis = 1)\n",
    "    #define parameters of the model and update functions using adadelta\n",
    "    params = classifier.params\n",
    "    for conv_layer in conv_layers:\n",
    "        params += conv_layer.params\n",
    "    if non_static:\n",
    "        #if word vectors are allowed to change, add them as model parameters\n",
    "        params += [Words]\n",
    "    cost = classifier.negative_log_likelihood(y)\n",
    "    dropout_cost = classifier.dropout_negative_log_likelihood(y)\n",
    "    grad_updates = sgd_updates_adadelta(params, dropout_cost, lr_decay, 1e-6, sqr_norm_lim)\n",
    "\n",
    "    #shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate\n",
    "    #extra data (at random)\n",
    "    np.random.seed(3435)\n",
    "    if datasets[0].shape[0] % batch_size > 0:\n",
    "        extra_data_num = batch_size - datasets[0].shape[0] % batch_size\n",
    "        rand_perm = np.random.permutation(range(len(datasets[0])))\n",
    "        train_set_x = datasets[0][rand_perm]\n",
    "        train_set_y = datasets[1][rand_perm]\n",
    "        train_set_m = datasets[4][rand_perm]\n",
    "        extra_data_x = train_set_x[:extra_data_num]\n",
    "        extra_data_y = train_set_y[:extra_data_num]\n",
    "        extra_data_m = train_set_m[:extra_data_num]\n",
    "        new_data_x = np.append(datasets[0],extra_data_x,axis=0)\n",
    "        new_data_y = np.append(datasets[1],extra_data_y,axis=0)\n",
    "        new_data_m = np.append(datasets[4],extra_data_m,axis=0)\n",
    "    else:\n",
    "        new_data_x = datasets[0]\n",
    "        new_data_y = datasets[1]\n",
    "        new_data_m = datasets[4]\n",
    "    rand_perm = np.random.permutation(range(len(new_data_x)))\n",
    "    new_data_x = new_data_x[rand_perm]\n",
    "    new_data_y = new_data_y[rand_perm]\n",
    "    new_data_m = new_data_m[rand_perm]\n",
    "    n_batches = new_data_x.shape[0]/batch_size\n",
    "    n_train_batches = int(np.round(n_batches*0.9))\n",
    "    #divide train set into train/val sets\n",
    "    test_set_x = datasets[2]\n",
    "    test_set_y = np.asarray(datasets[3],\"int32\")\n",
    "    test_set_m = datasets[5]\n",
    "    train_set_x, train_set_y, train_set_m = shared_dataset((new_data_x[:n_train_batches*batch_size], new_data_y[:n_train_batches*batch_size], new_data_m[:n_train_batches*batch_size]))\n",
    "    val_set_x, val_set_y, val_set_m = shared_dataset((new_data_x[n_train_batches*batch_size:], new_data_y[n_train_batches*batch_size:], new_data_m[n_train_batches*batch_size:]))\n",
    "    n_val_batches = n_batches - n_train_batches\n",
    "    val_model = theano.function([index], classifier.errors(y),\n",
    "         givens={\n",
    "            x: val_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "             y: val_set_y[index * batch_size: (index + 1) * batch_size],\n",
    "              mair: val_set_m[index * batch_size: (index + 1) * batch_size]},##mairesse_change\n",
    "                                allow_input_downcast = True)\n",
    "\n",
    "    #compile theano functions to get train/val/test errors\n",
    "    test_model = theano.function([index], [classifier.errors(y), svm_data],\n",
    "             givens={\n",
    "                x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "                 y: train_set_y[index * batch_size: (index + 1) * batch_size],\n",
    "                  mair: train_set_m[index * batch_size: (index + 1) * batch_size]},##mairesse_change\n",
    "                                 allow_input_downcast=True)\n",
    "    train_model = theano.function([index], cost, updates=grad_updates,\n",
    "          givens={\n",
    "            x: train_set_x[index*batch_size:(index+1)*batch_size],\n",
    "              y: train_set_y[index*batch_size:(index+1)*batch_size],\n",
    "                mair: train_set_m[index * batch_size: (index + 1) * batch_size]},##mairesse_change\n",
    "                                  allow_input_downcast = True)\n",
    "\n",
    "    test_y_pred = classifier.predict(layer1_input)\n",
    "    test_error = T.sum(T.neq(test_y_pred, y))\n",
    "    true_p = T.sum(test_y_pred*y)\n",
    "    false_p = T.sum(test_y_pred*T.mod(y+T.ones_like(y),T.constant(2,dtype='int32')))\n",
    "    false_n = T.sum(y*T.mod(test_y_pred+T.ones_like(y),T.constant(2,dtype='int32')))\n",
    "    test_model_all = theano.function([x, y,\n",
    "                                        mair##mairesse_change\n",
    "                                        ]\n",
    "                                    , [test_error, true_p, false_p, false_n, svm_data], allow_input_downcast = True)\n",
    "\n",
    "    test_batches = test_set_x.shape[0]/batch_size;\n",
    "\n",
    "\n",
    "    #start training over mini-batches\n",
    "    print '... training'\n",
    "    epoch = 0\n",
    "    best_val_perf = 0\n",
    "    val_perf = 0\n",
    "    test_perf = 0\n",
    "    fscore = 0\n",
    "    cost_epoch = 0\n",
    "    while (epoch < n_epochs):\n",
    "        start_time = time.time()\n",
    "        epoch = epoch + 1\n",
    "        if shuffle_batch:\n",
    "            for minibatch_index in np.random.permutation(range(n_train_batches)):\n",
    "                cost_epoch = train_model(minibatch_index)\n",
    "                set_zero(zero_vec)\n",
    "        else:\n",
    "            for minibatch_index in xrange(n_train_batches):\n",
    "                cost_epoch = train_model(minibatch_index)\n",
    "                set_zero(zero_vec)\n",
    "        train_losses = [test_model(i) for i in xrange(n_train_batches)]\n",
    "        train_perf = 1 - np.mean([loss[0] for loss in train_losses])\n",
    "        val_losses = [val_model(i) for i in xrange(n_val_batches)]\n",
    "        val_perf = 1- np.mean(val_losses)\n",
    "        epoch_perf = 'epoch: %i, training time: %.2f secs, train perf: %.2f %%, val perf: %.2f %%' % (epoch, time.time()-start_time, train_perf * 100., val_perf*100.)\n",
    "        print(epoch_perf)\n",
    "        ofile.write(epoch_perf+\"\\n\")\n",
    "        ofile.flush()\n",
    "        if val_perf >= best_val_perf:\n",
    "            best_val_perf = val_perf\n",
    "            test_loss_list = [test_model_all(test_set_x[idx*batch_size:(idx+1)*batch_size], test_set_y[idx*batch_size:(idx+1)*batch_size],\n",
    "            test_set_m[idx*batch_size:(idx+1)*batch_size]##mairesse_change\n",
    "            ) for idx in xrange(test_batches)]\n",
    "            if test_set_x.shape[0]>test_batches*batch_size:\n",
    "                test_loss_list.append(test_model_all(test_set_x[test_batches*batch_size:], test_set_y[test_batches*batch_size:],\n",
    "                test_set_m[test_batches*batch_size:]##mairesse_change\n",
    "                ))\n",
    "            test_loss_list_temp=test_loss_list\n",
    "            test_loss_list=np.asarray([t[:-1] for t in test_loss_list])\n",
    "            test_loss = np.sum(test_loss_list[:, 0])/float(test_set_x.shape[0])\n",
    "            test_perf = 1- test_loss\n",
    "            tp = np.sum(test_loss_list[:, 1])\n",
    "            fp = np.sum(test_loss_list[:, 2])\n",
    "            fn = np.sum(test_loss_list[:, 3])\n",
    "            tn = test_set_x.shape[0]-(tp+fp+fn)\n",
    "            fscore=np.mean([2*tp/float(2*tp+fp+fn), 2*tn/float(2*tn+fp+fn)])\n",
    "            svm_test=np.concatenate([t[-1] for t in test_loss_list_temp], axis=0)\n",
    "            svm_train=np.concatenate([t[1] for t in train_losses], axis=0)\n",
    "            output=\"Test result: accu: \"+str(test_perf)+\", macro_fscore: \"+str(fscore)+\"\\ntp: \"+str(tp)+\" tn:\"+str(tn)+\" fp: \"+str(fp)+\" fn: \"+str(fn)\n",
    "            print output\n",
    "            ofile.write(output+\"\\n\")\n",
    "            ofile.flush()\n",
    "            # dump train and test features\n",
    "            cPickle.dump(svm_test, open(\"cvte\"+str(attr)+str(cv)+\".p\", \"wb\"))\n",
    "            cPickle.dump(svm_train, open(\"cvtr\"+str(attr)+str(cv)+\".p\", \"wb\"))\n",
    "        updated_epochs = refresh_epochs()\n",
    "        if updated_epochs!=None and n_epochs!=updated_epochs:\n",
    "            n_epochs = updated_epochs\n",
    "            print 'Epochs updated to '+str(n_epochs)\n",
    "    return test_perf, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac02ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_=[0.3505,-0.413255,0.707633,-0.689787,-0.782389,-0.917808,-0.898268,-0.212531,-0.966792,0.060858,-0.090642,0.960495,-0.334764,0.245395,-1.189896,0,-0.04277,- 0.794944,-0.421201,-0.795527,-0.658629,0.168105,-0.101839,-0.593315,-0.624052,-0.029985,0.892479,-0.173279,-0.086726,0.178514,-0.755016,-0.08223,-0.303087,-0.089284,0.370296,- 1.109326,0.597274,-0.237741,-0.02349,1.805201,0.636188,-0.32495,-0.623239,-0.8578,0.147979,-0.501325,-0.793716,-0.527484,-0.551256,-0.465417,-0.35833,-0.013778,0.907993,-0.72945 ,-0.658996,1.077317,0.25876,0.293951,0.891778,3.131572,2.121563,-0.415617,-0.480161,0.058529,-0.147126,-0.280398,-0.086094,-0.707109,1.043631,-0.073676,0.582284,0.475846,-0.37208,-0.126497 ,0.262436,0.422855,-0.451544,0.648584,0.241039,4.992247,3.646778,4.82255,4.706556,4.755983]\n",
    "len(list_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
